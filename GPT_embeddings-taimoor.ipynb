{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa004a8",
   "metadata": {},
   "source": [
    "# GPT with open source models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0700db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from langchain_core.documents import Document\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b27c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_embeddings(model_name):\n",
    "    \"\"\"Initialize the HuggingFace embedding model.\"\"\"\n",
    "    return HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c52c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_embeddings(embeddings_dir, model_name):\n",
    "    \"\"\"Create a FAISS database from a single PDF file (book), with citation metadata for each page.\"\"\"\n",
    "    hf_embed = initialize_embeddings(model_name)\n",
    "\n",
    "    # Load the single PDF file\n",
    "    loader = PyPDFLoader('crime-and-punishment.pdf')\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for idx, page in enumerate(tqdm(pages, desc=\"Processing pages\", ncols=100)):\n",
    "        # Add metadata with the page number\n",
    "        metadata = {\n",
    "            \"page\": idx + 1 \n",
    "        }\n",
    "        documents.append(Document(page_content=page.page_content, metadata=metadata))\n",
    "\n",
    "    # Create the FAISS database from the documents and embeddings\n",
    "    print(\"Creating FAISS database from pages...\")\n",
    "    db = FAISS.from_documents(documents, embedding=hf_embed)\n",
    "\n",
    "    # Save the FAISS database locally\n",
    "    db.save_local(embeddings_dir)\n",
    "    print(\"Creating embeddings with metadata completed.\")\n",
    "    return db\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d985f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_dir, model_name):\n",
    "    \"\"\"Load the existing FAISS database, allowing dangerous deserialization.\"\"\"\n",
    "    hf_embed = initialize_embeddings(model_name)\n",
    "    try:\n",
    "        db = FAISS.load_local(embeddings_dir, hf_embed, allow_dangerous_deserialization=True)\n",
    "        print(\"Loaded the embeddings with metadata.\")\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load embeddings: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8844220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vector_store(embeddings_dir, model_name):\n",
    "    \"\"\"Initialize or load the FAISS database.\"\"\"\n",
    "    if not os.path.exists(embeddings_dir):\n",
    "        print(\"Creating new embeddings from PDF files...\")\n",
    "        return create_embeddings(embeddings_dir, model_name)\n",
    "    else:\n",
    "        print(\"Loading existing embeddings...\")\n",
    "        return load_embeddings(embeddings_dir, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0245155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qa_chain(llm, prompt_template):\n",
    "    \"\"\"Initialize the QA chain with the provided language model and prompt template.\"\"\"\n",
    "    return load_qa_chain(llm=llm, chain_type=\"stuff\", prompt=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb59617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing vector store...\n",
      "Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taimoor\\AppData\\Local\\Temp\\ipykernel_12380\\2594320127.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(model_name=model_name)\n",
      "C:\\Users\\Taimoor\\Assignment_Cogent\\assignment\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the embeddings with metadata.\n",
      "CPU times: total: 9.41 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_dir = os.path.join(os.getcwd(), \"Crime_and_Punishment\")\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# model_name = \"BAAI/bge-small-en\"\n",
    "# model_name = \"thenlper/gte-base\"\n",
    "\n",
    "# Initialize vector store (create or load)\n",
    "print(\"Initializing vector store...\")\n",
    "db = initialize_vector_store(embeddings_dir, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52ab273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.similarity_search('who is Fyodor Dostoevsky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90b40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instruction_text = (\"\"\" You are an expert literature guide helping students understand the novel Crime and Punishment by Fyodor Dostoevsky. Your task is to summarize the provided text in a clear, concise, and engaging manner, keeping in mind the following points:\n",
    "Main Ideas: Clearly outline the key events, characters, and philosophical themes in the text. Ensure the summary highlights critical aspects like internal conflicts, moral dilemmas, and character motivations.\n",
    "Tone and Style: Maintain the depth and seriousness of Dostoevsky’s narrative while making it accessible for students. Use simple but precise language to explain complex ideas.\n",
    "Key Themes: Highlight important themes, such as morality, justice, redemption, suffering, and the social issues of poverty and isolation. Relate these themes to the actions and choices of the characters.\n",
    "Relevance to Students: Provide insights into how the characters' struggles and themes connect to broader human experiences, encouraging reflection and engagement.\n",
    "Symbolism and Analysis: If applicable, briefly explain significant symbols or imagery (e.g., dreams, the cityscape) and their contribution to the novel’s message.\n",
    "Your summary length should be 300 words easy to read, and help students grasp both the plot and the deeper meaning of the text. Avoid unnecessary details or overly complex language. Instead, focus on creating a summary that sparks curiosity and encourages further exploration of the novel\"\"\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103397c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=instruction_text + \"\\n\\nContext: {context}\\n\\nQuestion: {question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9dd4cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" You are an expert literature guide helping students understand the novel Crime and Punishment by Fyodor Dostoevsky. Your task is to summarize the provided text in a clear, concise, and engaging manner, keeping in mind the following points:\\nMain Ideas: Clearly outline the key events, characters, and philosophical themes in the text. Ensure the summary highlights critical aspects like internal conflicts, moral dilemmas, and character motivations.\\nTone and Style: Maintain the depth and seriousness of Dostoevsky’s narrative while making it accessible for students. Use simple but precise language to explain complex ideas.\\nKey Themes: Highlight important themes, such as morality, justice, redemption, suffering, and the social issues of poverty and isolation. Relate these themes to the actions and choices of the characters.\\nRelevance to Students: Provide insights into how the characters' struggles and themes connect to broader human experiences, encouraging reflection and engagement.\\nSymbolism and Analysis: If applicable, briefly explain significant symbols or imagery (e.g., dreams, the cityscape) and their contribution to the novel’s message.\\nYour summary length should be 300 words easy to read, and help students grasp both the plot and the deeper meaning of the text. Avoid unnecessary details or overly complex language. Instead, focus on creating a summary that sparks curiosity and encourages further exploration of the novel\\n\\nContext: {context}\\n\\nQuestion: {question}\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f2c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taimoor\\AppData\\Local\\Temp\\ipykernel_12380\\3737860111.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Instantiate the model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",       \n",
    "    temperature=0.7,   \n",
    "    max_tokens=None,    \n",
    "    timeout=None,      \n",
    "    api_key=api_key, #os.getenv(\"OPENAI_API_KEY\"), \n",
    " \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86473e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taimoor\\AppData\\Local\\Temp\\ipykernel_12380\\835977039.py:3: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  return load_qa_chain(llm=llm, chain_type=\"stuff\", prompt=prompt_template)\n"
     ]
    }
   ],
   "source": [
    "chain = initialize_qa_chain(llm, qa_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7b98f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 21:51:20,497 - INFO - Summarizing pages 1 to 40 (1/20)...\n",
      "2024-11-21 21:51:34,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:51:34,551 - INFO - Summarizing pages 41 to 80 (2/20)...\n",
      "2024-11-21 21:51:39,398 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:51:39,404 - INFO - Summarizing pages 81 to 120 (3/20)...\n",
      "2024-11-21 21:51:44,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:51:44,876 - INFO - Summarizing pages 121 to 160 (4/20)...\n",
      "2024-11-21 21:51:50,488 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:51:50,493 - INFO - Summarizing pages 161 to 200 (5/20)...\n",
      "2024-11-21 21:52:00,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:00,477 - INFO - Summarizing pages 201 to 240 (6/20)...\n",
      "2024-11-21 21:52:06,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:06,839 - INFO - Summarizing pages 241 to 280 (7/20)...\n",
      "2024-11-21 21:52:13,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:13,480 - INFO - Summarizing pages 281 to 320 (8/20)...\n",
      "2024-11-21 21:52:18,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:18,590 - INFO - Summarizing pages 321 to 360 (9/20)...\n",
      "2024-11-21 21:52:23,814 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:23,821 - INFO - Summarizing pages 361 to 400 (10/20)...\n",
      "2024-11-21 21:52:36,558 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:36,567 - INFO - Summarizing pages 401 to 440 (11/20)...\n",
      "2024-11-21 21:52:41,558 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:41,562 - INFO - Summarizing pages 441 to 480 (12/20)...\n",
      "2024-11-21 21:52:46,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:46,816 - INFO - Summarizing pages 481 to 520 (13/20)...\n",
      "2024-11-21 21:52:52,122 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:52,130 - INFO - Summarizing pages 521 to 560 (14/20)...\n",
      "2024-11-21 21:52:57,534 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:52:57,545 - INFO - Summarizing pages 561 to 600 (15/20)...\n",
      "2024-11-21 21:53:02,320 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:02,327 - INFO - Summarizing pages 601 to 640 (16/20)...\n",
      "2024-11-21 21:53:09,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:09,073 - INFO - Summarizing pages 641 to 680 (17/20)...\n",
      "2024-11-21 21:53:14,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:14,998 - INFO - Summarizing pages 681 to 720 (18/20)...\n",
      "2024-11-21 21:53:20,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:20,301 - INFO - Summarizing pages 721 to 760 (19/20)...\n",
      "2024-11-21 21:53:25,567 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:25,576 - INFO - Summarizing pages 761 to 767 (20/20)...\n",
      "2024-11-21 21:53:31,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-21 21:53:31,277 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,294 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,302 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,308 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,316 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,320 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,325 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,337 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,344 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,351 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,364 - INFO - Custom font loaded successfully.\n",
      "2024-11-21 21:53:31,810 - INFO - PDF saved as 'Summarized_Crime Report.pdf'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fpdf import FPDF\n",
    "import logging\n",
    "\n",
    "# Constants\n",
    "MAX_PAGES = 20  # Maximum allowed PDF pages\n",
    "WORDS_PER_PAGE = 300  # Approximate words per page\n",
    "FONT_PATH = \"./arial-unicode-ms.ttf\"  # Path to the custom font file\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def ask_question(db, chain, page_range, num_references=1):\n",
    "    \"\"\"Ask a question to summarize content for a specific page range.\"\"\"\n",
    "    question = f\"Summarize the content of pages {page_range[0]} to {page_range[1]} of the book.\"\n",
    "\n",
    "    docs_db = db.similarity_search(question, k=num_references)\n",
    "    if not docs_db:\n",
    "        logging.warning(f\"No similar documents found for pages {page_range}.\")\n",
    "        return f\"No summary available for pages {page_range[0]} to {page_range[1]}.\"\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Page: {doc.metadata.get('page', 'N/A')}\\n{doc.page_content}\"\n",
    "        for doc in docs_db\n",
    "    )\n",
    "\n",
    "    response = chain({\n",
    "        \"input_documents\": docs_db,\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"existing_answer\": \"\"\n",
    "    }, return_only_outputs=True)\n",
    "\n",
    "    if not response.get('output_text') or response['output_text'] == \"The answer is not in the knowledge base.\":\n",
    "        logging.warning(f\"Failed to summarize pages {page_range}.\")\n",
    "        return f\"No summary available for pages {page_range[0]} to {page_range[1]}.\"\n",
    "\n",
    "    return response['output_text']\n",
    "\n",
    "\n",
    "def truncate_or_split_summaries(summaries):\n",
    "    \"\"\"Ensure summaries fit within the allowed page limit by truncating or summarizing further.\"\"\"\n",
    "    total_words = sum(len(summary.split()) for summary in summaries)\n",
    "    max_words = MAX_PAGES * WORDS_PER_PAGE\n",
    "\n",
    "    if total_words > max_words:\n",
    "        logging.info(\"Summaries exceed maximum allowed words. Adjusting...\")\n",
    "        adjusted_summaries = []\n",
    "        for summary in summaries:\n",
    "            truncated = \" \".join(summary.split()[:max_words // len(summaries)])\n",
    "            adjusted_summaries.append(truncated)\n",
    "        return adjusted_summaries\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def configure_font(pdf):\n",
    "    \"\"\"Configure the PDF font with fallback.\"\"\"\n",
    "    if os.path.exists(FONT_PATH):\n",
    "        try:\n",
    "            pdf.add_font('ArialUnicode', '', FONT_PATH, uni=True)\n",
    "            pdf.add_font('ArialUnicode', 'B', FONT_PATH, uni=True)\n",
    "            pdf.set_font('ArialUnicode', size=12)\n",
    "            logging.info(\"Custom font loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Font loading failed: {e}. Falling back to default.\")\n",
    "            pdf.set_font('Arial', size=12)\n",
    "    else:\n",
    "        logging.warning(\"Custom font file not found. Using default font.\")\n",
    "        pdf.set_font('Arial', size=12)\n",
    "\n",
    "\n",
    "def write_answers_to_pdf(answers, output_filename):\n",
    "    \"\"\"Write the answers into a PDF file, ensuring the output fits within 20 pages.\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=16)\n",
    "    pdf.add_page()\n",
    "\n",
    "    configure_font(pdf)\n",
    "    pdf.set_font(\"ArialUnicode\", style='B', size=16)\n",
    "    pdf.cell(200, 10, txt=\"Summary of Crime and Punishment\", ln=True, align='C')\n",
    "    pdf.ln(10)\n",
    "\n",
    "    total_pages = 1  # Start with the first page already added\n",
    "\n",
    "    for idx, answer in enumerate(answers, start=1):\n",
    "        if total_pages > MAX_PAGES:\n",
    "            break\n",
    "\n",
    "        pdf.set_font(\"ArialUnicode\", style='B', size=14)\n",
    "        pdf.cell(0, 10, ln=True)\n",
    "        pdf.ln(5)\n",
    "\n",
    "        pdf.set_font(\"ArialUnicode\", size=11)\n",
    "        clean_answer = answer.encode('latin1', 'replace').decode('latin1')\n",
    "        pdf.multi_cell(0, 10, clean_answer)\n",
    "        pdf.ln(10)\n",
    "\n",
    "        if pdf.get_y() > 250:  # Add a new page if nearing the bottom\n",
    "            pdf.add_page()\n",
    "            configure_font(pdf)\n",
    "            total_pages += 1\n",
    "\n",
    "    pdf.output(output_filename)\n",
    "    logging.info(f\"PDF saved as '{output_filename}'\")\n",
    "\n",
    "\n",
    "def calculate_page_ranges(total_pages, chunk_size):\n",
    "    \"\"\"Calculate page ranges for chunked summarization.\"\"\"\n",
    "    return [(start, min(start + chunk_size - 1, total_pages)) for start in range(1, total_pages + 1, chunk_size)]\n",
    "\n",
    "\n",
    "def generate_summaries(db, chain, total_pages=767, page_chunk=40):\n",
    "    \"\"\"Generate summaries for the entire book in chunks.\"\"\"\n",
    "    page_ranges = calculate_page_ranges(total_pages, page_chunk)\n",
    "    summaries = []\n",
    "\n",
    "    for idx, page_range in enumerate(page_ranges):\n",
    "        logging.info(f\"Summarizing pages {page_range[0]} to {page_range[1]} ({idx + 1}/{len(page_ranges)})...\")\n",
    "        summary = ask_question(db, chain, page_range)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    summaries = truncate_or_split_summaries(summaries)\n",
    "    write_answers_to_pdf(summaries, \"Summarized_Crime Report.pdf\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the summarization and PDF generation.\"\"\"\n",
    "\n",
    "    generate_summaries(db, chain)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339ae36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment",
   "language": "python",
   "name": "assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
